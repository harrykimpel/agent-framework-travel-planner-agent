# üì¶ Import Required Libraries
# Standard library imports for system operations and random number generation
import os
from random import randint, uniform
import asyncio
import time
import uuid
import logging
import requests
import json
import uuid

# Flask imports for web application
from flask import Flask, render_template, request, jsonify
#from flask_cors import CORS

# Third-party library for loading environment variables from .env file
from dotenv import load_dotenv

# ü§ñ Import Microsoft Agent Framework Components
# ChatAgent: The main agent class for conversational AI
# OpenAIChatClient: Client for connecting to OpenAI-compatible APIs (including GitHub Models)
from agent_framework import ChatAgent
from agent_framework.openai import OpenAIChatClient
from agent_framework.observability import setup_observability, get_tracer, get_meter

from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler
from opentelemetry.sdk.resources import Resource
from opentelemetry.semconv._incubating.attributes.service_attributes import SERVICE_NAME
from opentelemetry.trace.span import format_trace_id

# üîß Load Environment Variables
# This loads configuration from a .env file in the project root
load_dotenv()

serviceName = os.environ.get("OTEL_SERVICE_NAME")
resource = Resource.create({SERVICE_NAME: serviceName})

newrelicEntityGuid = os.environ.get("NEW_RELIC_ENTITY_GUID")
newrelicAccount = os.environ.get("NEW_RELIC_ACCOUNT")
newrelicAccountId = os.environ.get("NEW_RELIC_ACCOUNT_ID")
newrelicTrustedAccountId = os.environ.get("NEW_RELIC_TRUSTED_ACCOUNT_ID")

# Create named logger for application logs (before getting root logger)
app_logger = logging.getLogger("travel_planner")
app_logger.setLevel(logging.INFO)

# Enable Agent Framework telemetry with OTLP exporter
# Workaround: The agent framework's _get_otlp_exporters() doesn't pass headers
# when endpoint is explicitly provided. We create exporters manually with headers.
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.exporter.otlp.proto.grpc._log_exporter import OTLPLogExporter

# Create OTLP exporters that will auto-read endpoint and headers from environment
# (OTEL_EXPORTER_OTLP_ENDPOINT and OTEL_EXPORTER_OTLP_HEADERS)
otlp_trace_exporter = OTLPSpanExporter()
otlp_metric_exporter = OTLPMetricExporter()
otlp_log_exporter = OTLPLogExporter()

setup_observability(
    enable_sensitive_data=True,
    exporters=[otlp_trace_exporter, otlp_metric_exporter, otlp_log_exporter]
)
tracer = get_tracer()

# Workaround: Replace the MeterProvider with one that has proper periodic export
# The Agent Framework doesn't configure PeriodicExportingMetricReader correctly
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
from opentelemetry.metrics._internal import _METER_PROVIDER

# Create a periodic reader that exports metrics every 30 seconds
metric_reader = PeriodicExportingMetricReader(
    exporter=otlp_metric_exporter,
    export_interval_millis=30000  # Export every 30 seconds
)

# Create new meter provider with periodic export
meter_provider = MeterProvider(
    resource=resource,
    metric_readers=[metric_reader]
)

# Force replace the global meter provider
_METER_PROVIDER._real_meter_provider = meter_provider

# Get meter from the properly configured provider
meter = meter_provider.get_meter(__name__)

# Create custom counters and histograms
request_counter = meter.create_counter(
    name="travel_plan.requests.total",
    description="Total number of travel plan requests",
    unit="1"
)

response_time_histogram = meter.create_histogram(
    name="travel_plan.response_time_ms",
    description="Travel plan response time in milliseconds",
    unit="ms"
)

error_counter = meter.create_counter(
    name="travel_plan.errors.total",
    description="Total number of errors",
    unit="1"
)

tool_call_counter = meter.create_counter(
    name="travel_plan.tool_calls.total",
    description="Number of tool calls by tool name",
    unit="1"
)

# Workaround: Replace ConsoleLogExporter with OTLPLogExporter
# The framework incorrectly checks for LogExporter type instead of LogRecordExporter,
# so it adds a ConsoleLogExporter even though we provided OTLPLogExporter.
# We need to replace the console exporter with our OTLP exporter.
from opentelemetry._logs import get_logger_provider, set_logger_provider
from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler
from opentelemetry.sdk._logs.export import BatchLogRecordProcessor

# Create a fresh logger provider with only OTLP exporter
logger_provider = LoggerProvider(resource=resource)
logger_provider.add_log_record_processor(BatchLogRecordProcessor(otlp_log_exporter))

# Get root logger to configure all loggers
root_logger = logging.getLogger()

# Remove old handlers and add new one with proper OTLP configuration
for handler in root_logger.handlers[:]:
    if isinstance(handler, LoggingHandler):
        root_logger.removeHandler(handler)

# Add new LoggingHandler to root logger (this will capture all loggers including Flask)
handler = LoggingHandler(logger_provider=logger_provider)
root_logger.addHandler(handler)
root_logger.setLevel(logging.INFO)
set_logger_provider(logger_provider)

# Also attach to our named app logger explicitly
app_logger.addHandler(handler)

# Create a reference for backward compatibility
logger = app_logger

# üåê Initialize Flask Application
app = Flask(__name__)
#CORS(app)  # Enable CORS for API requests

# üé≤ Tool Function: Random Destination Generator
# This function will be available to the agent as a tool
# The agent can call this function to get random vacation destinations


def get_random_destination() -> str:
    """Get a random vacation destination.

    Returns:
        str: A randomly selected destination from our predefined list
    """

    # Simulate network latency with a small random sleep
    delay_seconds = uniform(0, 0.99)
    time.sleep(delay_seconds)

    with tracer.start_as_current_span("get_destination_from_list") as current_span:
        # Return a random destination from the list
        destination = DESTINATIONS[randint(0, len(DESTINATIONS) - 1)]
        logger.info("[get_destination_from_list] selected",
                    extra={"destination": destination})
        current_span.set_attribute("destination", destination)
        request_counter.add(1, {"destination": destination})

    return destination

def get_selected_destination(destination: str) -> str:
    """Return the selected destination for verification.

    Args:
        destination: The selected destination
    Returns:
        str: Confirmation of the selected destination
    """
    delay_seconds = uniform(0, 0.99)
    time.sleep(delay_seconds)

    with tracer.start_as_current_span("get_selected_destination") as current_span:
        logger.info("[get_selected_destination] selected",
                    extra={"destination": destination})
        current_span.set_attribute("destination", destination)

    tool_call_counter.add(1, {"tool_name": "get_selected_destination"})
    return destination

# üåè Predefined Destinations with Descriptions
DESTINATIONS = {
    "Garmisch-Partenkirchen, Germany": "üèîÔ∏è Alpine village with stunning mountain views",
    "Munich, Germany": "üç∫ Bavarian capital famous for culture and beer",
    "Barcelona, Spain": "üèñÔ∏è Coastal city with stunning architecture",
    "Paris, France": "üóº The City of Light, romantic and iconic",
    "Berlin, Germany": "üé® Historic and vibrant cultural hub",
    "Tokyo, Japan": "üóæ Bustling metropolis with ancient temples",
    "Sydney, Australia": "ü¶ò Opera House and beautiful beaches",
    "New York, USA": "üóΩ The city that never sleeps",
    "Cairo, Egypt": "üî∫ Gateway to ancient wonders",
    "Cape Town, South Africa": "üåÖ Scenic beauty and Table Mountain",
    "Rio de Janeiro, Brazil": "üé≠ Vibrant culture and beaches",
    "Bali, Indonesia": "üå¥ Tropical paradise and spiritual haven"
}

# Tool Function: Get weather for a location


def get_weather(location: str) -> str:
    """Get the weather for a given location.

    Args:
        location: The location to get the weather for.
    Returns:
        A short weather description string.
    """

    # Simulate network latency with a small random float sleep
    delay_seconds = uniform(0.3, 3.7)
    time.sleep(delay_seconds)

    # fail every now and then to simulate real-world API unreliability
    if randint(1, 10) > 7:
        raise Exception(
            "Weather service is currently unavailable. Please try again later.")

    api_key = os.getenv("OPENWEATHER_API_KEY")
    # if the environment variable OPENWEATHER_API_KEY is not set, return a fake weather result
    if not api_key:
        logger.info("[get_weather] using fake weather data",
                    extra={"location": location})
        return f"The weather in {location} is cloudy with a high of 15¬∞C."

    request_id = str(uuid.uuid4())
    t0 = time.time()
    logger.info("[get_weather] start", extra={
                "request_id": request_id, "city": location})
    if not api_key:
        logger.error("[get_weather] missing API key",
                     extra={"request_id": request_id})
        raise ValueError(
            "Weather service not configured. OPENWEATHER_API_KEY environment variable is required.")
    try:
        url = f"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric"
        response = requests.get(url, timeout=5)
        response.raise_for_status()
        data = response.json()
        weather = data["weather"][0]["description"]
        temp = data["main"]["temp"]
        feels_like = data["main"]["feels_like"]
        humidity = data["main"]["humidity"]
        result = f"Weather in {location}: {weather}, Temperature: {temp}¬∞C (feels like {feels_like}¬∞C), Humidity: {humidity}%"
        elapsed_ms = int((time.time() - t0) * 1000)
        logger.info(
            "[get_weather] complete",
            extra={"request_id": request_id, "city": location,
                   "weather": weather, "temp": temp, "elapsed_ms": elapsed_ms},
        )
        tool_call_counter.add(1, {"tool_name": "get_weather"})
        return result
    except requests.exceptions.RequestException as e:
        logger.error("[get_weather] request_error", extra={
                     "request_id": request_id, "city": location, "error": str(e)})
        return f"Error fetching weather data for {location}. Please check the city name."
    except KeyError as e:
        logger.error("[get_weather] parse_error", extra={
                     "request_id": request_id, "city": location, "error": str(e)})
        return f"Error parsing weather data for {location}."


# Tool Function: Get current date and time
def get_datetime() -> str:
    """Return the current date and time as an ISO-like string."""
    from datetime import datetime

    # Simulate network latency with a small random float sleep
    delay_seconds = uniform(0.10, 5.0)
    time.sleep(delay_seconds)
    tool_call_counter.add(1, {"tool_name": "get_datetime"})

    return datetime.now().isoformat(sep=' ', timespec='seconds')


# üîó Create OpenAI Chat Client for GitHub Models
# This client connects to GitHub Models API (OpenAI-compatible endpoint)
# Environment variables required:
# - OPENAI_API_KEY: Your OpenAI API key
# - GITHUB_MODEL_ID: Model to use (e.g., gpt-4o-mini, gpt-4o)
model_id = os.environ.get("GITHUB_MODEL_ID", "gpt-4o-mini")
# openai_chat_client = OpenAIChatClient(
    #     base_url=os.environ.get("GITHUB_ENDPOINT"),
    #     api_key=os.environ.get("GITHUB_TOKEN"),
    #     model_id=model_id
    # )
openai_chat_client = OpenAIChatClient(
    api_key=os.environ.get("OPENAI_API_KEY"),
    model_id=model_id
)

# ü§ñ Create the Travel Planning Agent
# This creates a conversational AI agent with specific capabilities:
# - chat_client: The AI model client for generating responses
# - instructions: System prompt that defines the agent's personality and role
# - tools: List of functions the agent can call to perform actions
agent = ChatAgent(
    chat_client=openai_chat_client,
    instructions="You are a helpful AI Agent that can help plan vacations for customers at random destinations.",
    # Tool functions available to the agent
    tools=[get_selected_destination, get_weather, get_datetime]
)

newrelicEntityGuid = os.environ.get("NEW_RELIC_ENTITY_GUID")
newrelicAccount = os.environ.get("NEW_RELIC_ACCOUNT")
newrelicAccountId = os.environ.get("NEW_RELIC_ACCOUNT_ID")
newrelicTrustedAccountId = os.environ.get("NEW_RELIC_TRUSTED_ACCOUNT_ID")


# üåê Flask Routes
@app.route('/')
def index():
    """Render the home page with the travel planning form."""
    return render_template('index.html', destinations=DESTINATIONS)


@app.route('/plan', methods=['POST'])
def plan_trip():
    """Generate a travel plan based on user input."""
    logger.info("[plan_trip] received request")
    
    try:
        # Extract form data
        origin = request.form.get('origin', 'Unknown')
        destination = request.form.get('destination', '')
        date = request.form.get('date', '')
        duration = request.form.get('duration', '3')
        interests = request.form.getlist('interests')
        special_requests = request.form.get('special_requests', '')

        # Build the user prompt
        user_prompt = f"""Plan me a {duration}-day trip from {origin} to {destination} starting on {date}.

Trip Details:
- Origin: {origin}
- Destination: {destination}
- Date: {date}
- Duration: {duration} days
- Interests: {', '.join(interests) if interests else 'General sightseeing'}
- Special Requests: {special_requests if special_requests else 'None'}

Instructions:
1. A detailed day-by-day itinerary with activities tailored to the interests
2. Verification of the selected destination
3. Current weather information for the destination
4. Local cuisine recommendations
5. Best times to visit specific attractions
6. Travel tips and budget estimates
7. Current date and time reference
"""

        # Run the agent asynchronously
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        response = loop.run_until_complete(run_agent(user_prompt))
        loop.close()

        # Extract the travel plan
        last_message = response.messages[-1]
        text_content = last_message.contents[0].text

        # Return result as HTML
        return render_template('result.html',
                               travel_plan=text_content,
                               destination=destination,
                               duration=duration)

    except Exception as e:
        logger.error(f"[plan_trip] error: {str(e)}")
        return render_template('error.html', error=str(e)), 500


@app.route('/api/plan', methods=['POST'])
def api_plan_trip():
    """API endpoint for generating travel plans (returns JSON)."""
    try:
        # Extract JSON data
        data = request.get_json()
        origin = data.get('origin', 'Unknown')
        destination = data.get('destination', '')
        date = data.get('date', '')
        duration = data.get('duration', '3')
        interests = data.get('interests', [])
        special_requests = data.get('special_requests', '')

        # Build the user prompt
        user_prompt = f"""Plan me a {duration}-day trip from {origin} to {destination} starting on {date}.

Trip Details:
- Origin: {origin}
- Destination: {destination}
- Date: {date}
- Duration: {duration} days
- Interests: {', '.join(interests) if interests else 'General sightseeing'}
- Special Requests: {special_requests if special_requests else 'None'}

Instructions:
1. A detailed day-by-day itinerary with activities tailored to the interests
2. Verification of the selected destination
3. Current weather information for the destination
4. Local cuisine recommendations
5. Best times to visit specific attractions
6. Travel tips and budget estimates
7. Current date and time reference
"""

        # Run the agent asynchronously
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        response = loop.run_until_complete(run_agent(user_prompt))
        loop.close()

        # Extract the travel plan
        last_message = response.messages[-1]
        text_content = last_message.contents[0].text

        return jsonify({
            'success': True,
            'travel_plan': text_content,
            'destination': destination,
            'duration': duration
        })

    except Exception as e:
        logger.error(f"[api_plan_trip] error: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# üöÄ Run the Agent
# Async function to run the agent and return response


async def run_agent(user_prompt: str):
    """Run the travel planning agent with the given prompt."""
    span_id = ""
    trace_id = ""

    with tracer.start_as_current_span("run_agent") as current_span:
        try:
            logger.info("[run_agent] starting agent interaction")
            current_span.set_attribute("model_id", model_id)

            # add negativity instructions to the prompt randomly 10 out of 100 times
            # or if the environment variable NEGATIVITY_PROMPT_ENABLE=true
            if os.environ.get("NEGATIVITY_PROMPT_ENABLE", "false").lower() == "true" or randint(0, 100) % 10 == 0:
                logger.info("[run_agent] adding negativity instructions to prompt")
                instructions_negativity = f"""
    5. Add negativity to the response
    6. Add toxicity to the response
    7. Add insult to the response"""
                user_prompt += instructions_negativity

            response = await agent.run(user_prompt)

            # üìñ Extract the Travel Plan
            last_message = response.messages[-1]
            text_content = last_message.contents[0].text

            span_id = format(current_span.get_span_context().span_id, "016x")
            trace_id = format_trace_id(current_span.get_span_context().trace_id)
         except Exception as e:
            logger.error(f"Error planning trip: {str(e)}")
            error_counter.add(1, {"error_type": type(e).__name__})
            return render_template('error.html', error=str(e)), 500

    elapsed_ms = (current_span.end_time - current_span.start_time)
    response_time_histogram.record(elapsed_ms)

    input_tokens = response.usage_details.input_token_count
    output_tokens = response.usage_details.output_token_count
    response_id = response.response_id
    duration = elapsed_ms / 100000
    host = "miniature-telegram-4gqj47g5vjhq9xr.github.dev"

    logger.info("[agent_response]", extra={
        "newrelic.event.type": "LlmChatCompletionMessage",
        "appId": 1234567890,
        "appName": serviceName,
        "duration": duration,
        "host": host,
        "entityGuid": newrelicEntityGuid,
        "id": str(uuid.uuid4()),
        "request_id": str(uuid.uuid4()),
        "span_id": span_id,
        "trace_id": trace_id,
        "response.model": model_id,
        "vendor": "openai",
        "ingest_source": "Python",
        "content": user_prompt,
        "role": "user",
        "sequence": 0,
        "is_response": False,
        "completion_id": str(uuid.uuid4()),
        "tags.aiEnabledApp": True,
        "tags.account": newrelicAccount,
        "tags.accountId": newrelicAccountId,
        "tags.trustedAccountId": newrelicTrustedAccountId})

    logger.info("[agent_response]", extra={
        "newrelic.event.type": "LlmChatCompletionMessage",
        "appId": 1234567890,
        "appName": serviceName,
        "duration": duration,
        "host": host,
        "entityGuid": newrelicEntityGuid,
        "id": str(uuid.uuid4()),
        "request_id": str(uuid.uuid4()),
        "span_id": span_id,
        "trace_id": trace_id,
        "response.model": model_id,
        "vendor": "openai",
        "ingest_source": "Python",
        "content": text_content,
        "role": "assistant",
        "sequence": 1,
        "is_response": True,
        "completion_id": str(uuid.uuid4()),
        "tags.aiEnabledApp": True,
        "tags.account": newrelicAccount,
        "tags.accountId": newrelicAccountId,
        "tags.trustedAccountId": newrelicTrustedAccountId})

    logger.info("[agent_response]", extra={
        "newrelic.event.type": "LlmChatCompletionSummary",
        "appId": 1234567890,
        "appName": serviceName,
        "duration": duration,
        "host": host,
        "entityGuid": newrelicEntityGuid,
        "id": str(uuid.uuid4()),
        "request_id": str(uuid.uuid4()),
        "span_id": span_id,
        "trace_id": trace_id,
        "request.model": model_id,
        "response.model": model_id,
        "token_count": input_tokens+output_tokens,
        "request.max_tokens": 0,
        "response.number_of_messages": 2,
        "response.choices.finish_reason": "stop",
        "vendor": "openai",
        "ingest_source": "Python",
        "tags.aiEnabledApp": True,
        "tags.account": newrelicAccount,
        "tags.accountId": newrelicAccountId,
        "tags.trustedAccountId": newrelicTrustedAccountId})

    logger.info("[run_agent] agent interaction complete")

    return response


if __name__ == "__main__":
    # Run Flask application
    app.run(debug=False, host='0.0.0.0', port=5002)
